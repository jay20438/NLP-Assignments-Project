{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "308wY6yyTrEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d841256a-199c-4ee7-b2e3-1f670d2e64af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "TiKIRhaHUW5L"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/NLP_A4/train_file.json\"\n",
        "val_path = \"/content/drive/MyDrive/NLP_A4/val_file.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HuoqqPfIUW8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd71b248-c459-49be-a866-89c6c4960b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'episode': 'utterance_3492', 'speakers': ['Phoebe', 'Eric', 'Phoebe', 'Eric', 'Phoebe'], 'emotions': ['surprise', 'fear', 'surprise', 'sadness', 'disgust'], 'utterances': ['You-you\\x85you had sex with Ursula?!', 'Uh, a little bit. She-she-she walked in and I thought she was you and I kissed her and', \"You didn't notice she was wearing different clothes?!\", 'Well I was just so excited to see you.', \"Oh. Ew! Ew! Ew! Ugh! Y'know what? This is too weird.\"], 'triggers': [1.0, 1.0, 0.0, 0.0, 0.0]}\n",
            "{'episode': 'utterance_3952', 'speakers': ['Monica', 'Monica', 'Phoebe', 'Joey', 'Joey', 'Joey', 'Rachel', 'Joey', 'Rachel', 'Rachel', 'Rachel', 'Rachel', 'Rachel', 'Joey', 'Monica'], 'emotions': ['disgust', 'disgust', 'anger', 'sadness', 'surprise', 'anger', 'neutral', 'anger', 'anger', 'anger', 'anger', 'fear', 'neutral', 'joy', 'anger'], 'utterances': [\"Dad, please don't pick your teeth out here!\", \"Alright, and if you're gonna put your feet up, why don't you sit on the-\", 'Monica, leave him alone', 'Will you hurry up?', \"Did you not hear me before when I told you that all of Janine's friends are dancers?!\", \"And that they're going to be drinking alot!\", \"No, I did, but tell me again, because it's so romantic.\", \"Well you're whippin' so slow! Can't you do it any faster?\", 'Joey!', 'Come on!', \"I don't wanna make any mistakes, alright?\", \"This is the only dessert and if I screw it up everybody's gonna be like \\x93Oh, remember that Thanksgiving when Rachel screwed up the trifle?\\x94\", \"So why don't you just let me worry about making the trifle and you just worry about eating it, alright?\", 'Oh I am!', \"Ross, if you don't tell them, then I will!\"], 'triggers': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}\n",
            "{'episode': 'utterance_3198', 'speakers': ['Older Scientist', 'Ross', 'Ross', 'Joey', 'Ross', 'Ross', 'Ross'], 'emotions': ['neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'fear'], 'utterances': [\"Dr. Geller, there's a seat over here.\", \"Thank you, Dr. Phillips, but I'm having my lunch at this table, here in the middle.\", \"I'm having lunch right here, with my good friend Joey, if he'll sit with me.\", 'I will sit with you Dr. Geller.', \"Y'know, we work in a museum of natural history, and yet there is something unnatural about the way we eat lunch.\", \"Now, I look around this cafeteria, and y'know what I see, I see-I see division.\", 'Division, between people in white coats and people in blue blazers, and I ask myself, \"My God why?!\"'], 'triggers': [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}\n",
            "{'episode': 'utterance_2834', 'speakers': ['Monica', 'Monica', 'Monica'], 'emotions': ['neutral', 'surprise', 'neutral'], 'utterances': [\"So, how'd the lasagne go over?\", 'Really?!', 'Good.'], 'triggers': [0.0, 0.0, 1.0]}\n",
            "{'episode': 'utterance_453', 'speakers': ['Kate', 'The Director', 'Kate'], 'emotions': ['joy', 'sadness', 'sadness'], 'utterances': ['Become a drama critic!', 'I am hurt!  A plague on both your houses!', 'By the way, he dumped me tonight after he read my review.'], 'triggers': [0.0, 0.0, 1.0]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def read_json_file(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "train_data = read_json_file(train_path)\n",
        "val_data = read_json_file(val_path)\n",
        "\n",
        "for i in range(5):\n",
        "    print(train_data[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRahjYwoUXMx",
        "outputId": "107f039f-fb90-48ca-e15e-1b322b750718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'episode': 'utterance_3421', 'speakers': ['Chandler', 'Joey', 'Chandler', 'Joey', 'Joey', 'Chandler', 'Joey', 'Joey', 'Joey', 'Chandler', 'Joey', 'Chandler', 'Joey', 'Chandler', 'Joey', 'Chandler', 'Joey'], 'emotions': ['anger', 'neutral', 'neutral', 'surprise', 'anger', 'disgust', 'neutral', 'neutral', 'neutral', 'anger', 'fear', 'surprise', 'neutral', 'sadness', 'sadness', 'surprise', 'neutral'], 'utterances': ['Hey! Hold on a minute, hold on a second. Do you think these pearls are nice?', \"I'd really prefer a mountain bike.\", \"Janice's birthday is coming up, I want to get her something speacial. Come in here with me.\", 'Whoa, whoa, whoa, wait, whoa.', 'Do you ah, want to get her something speacial, get her flowers, get her candy, get her gum, girls love gum.', \"That's a good idea, \\x91Dear Janice have a Hubba-Bubba birthday'. I would like to get her something serious.\", 'Oh, you want something serious.', \"Y'know what you should do, you should get her one of those um, barium enemas.\", 'Those are dead serious.', \"All right. Look, I'm gonna go in here, and you don't buy me anything ever.\", \"No, no, you can't, you can't, okay, you can't, you can't buy her pearls, you just can't, you can't, you can't.\", 'Why not?!', \"Oh God. Uh, okay, here's the thing, this is the thing, okay, the thing is...\", 'What is the thing?', \"Okay. I went down to the \\x91Mattress King' showroom and, and I saw Janice, kissing her ex-husband.\", 'What?', 'They were in his office.'], 'triggers': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}\n",
            "{'episode': 'utterance_119', 'speakers': ['Elizabeth', 'Ross', 'Paul', 'Ross', 'Paul', 'Ross', 'Paul', 'Ross', 'Paul', 'Ross', 'Ross', 'Ross', 'Paul', 'Ross'], 'emotions': ['neutral', 'joy', 'neutral', 'neutral', 'anger', 'surprise', 'anger', 'fear', 'neutral', 'neutral', 'neutral', 'fear', 'neutral', 'neutral'], 'utterances': ['This is my father, Paul Stevens. Dad, this is Ross Geller.', \"It-it's great to meet you Paul.\", \"I usually prefer Elizabeth's boyfriends to address me as Mr. Stevens.\", 'Of course, of course, Mr. Stevens.', 'So Ross, what your problem?', 'Eh-wh\\x97Excuse me?', \"Why can't you get a girlfriend your own age?\", \"That's funny. Umm\\x85.  It's not funny.\", 'I', 'Okay.', 'I can, I can see that.', 'Umm, but I think if you give me umm, one chance I can, I can change your mind.', 'Okay.', 'What?'], 'triggers': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}\n",
            "{'episode': 'utterance_510', 'speakers': ['Ross', 'Chandler', 'Ross', 'Chandler', 'Ross', 'Chandler', 'Ross', 'Chandler', 'Chandler'], 'emotions': ['neutral', 'neutral', 'neutral', 'joy', 'fear', 'joy', 'surprise', 'disgust', 'surprise'], 'utterances': [\"Ok, bye.  Well, Monica's not coming, it's just gonna be me and Rachel.\", \"Oh. Well, hold on camper, are you sure you've thought this thing through?\", \"It's laundry. The thinking through is minimal.\", \"It's just you and Rachel, just the two of you? This is a date. You're going on a date.\", 'Nuh-uh.', 'Yuh-huh.', \"So what're you saying here? I should shave again, pick up some wine, what?\", 'Well, you may wanna rethink the dirty underwear.', \"This is basically the first time she's gonna see your underwear\\x97you want it to be dirty?\"], 'triggers': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}\n",
            "{'episode': 'utterance_172', 'speakers': ['Rachel', 'Joey', 'Rachel', 'Joey', 'Rachel', 'Joey'], 'emotions': ['surprise', 'neutral', 'disgust', 'neutral', 'surprise', 'surprise'], 'utterances': ['I thought I was a complete idiot.', 'Hey, I\\x92m with you. He even asked me if I thought you\\x92d go out with him.', 'Oh! Oh, I think I\\x92m gonna throw up a little bit. What did you say?', 'I said no.', 'What?!', 'What? I\\x85I just figured since you\\x92re pregnant you\\x92re not gonna be seeing people.'], 'triggers': [0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}\n",
            "{'episode': 'utterance_3949', 'speakers': ['Monica', 'Monica', 'Phoebe', 'Joey', 'Joey', 'Joey', 'Rachel', 'Joey', 'Rachel', 'Rachel', 'Rachel', 'Rachel'], 'emotions': ['disgust', 'disgust', 'anger', 'sadness', 'surprise', 'anger', 'neutral', 'anger', 'anger', 'anger', 'anger', 'fear'], 'utterances': [\"Dad, please don't pick your teeth out here!\", \"Alright, and if you're gonna put your feet up, why don't you sit on the-\", 'Monica, leave him alone', 'Will you hurry up?', \"Did you not hear me before when I told you that all of Janine's friends are dancers?!\", \"And that they're going to be drinking alot!\", \"No, I did, but tell me again, because it's so romantic.\", \"Well you're whippin' so slow! Can't you do it any faster?\", 'Joey!', 'Come on!', \"I don't wanna make any mistakes, alright?\", \"This is the only dessert and if I screw it up everybody's gonna be like \\x93Oh, remember that Thanksgiving when Rachel screwed up the trifle?\\x94\"], 'triggers': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(val_data[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KxJsEgt5dgfX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfccfe24-94e1-4b7c-b229-ed85706664ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['episode', 'speakers', 'emotions', 'utterances', 'triggers'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "train_data[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCwQetiYdr9-",
        "outputId": "3e3a73ea-e5ba-4514-af27-4dcf322c01e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists for each feature in the training data\n",
        "train_episodes = []\n",
        "train_speakers = []\n",
        "train_emotions = []\n",
        "train_utterances = []\n",
        "train_triggers = []\n",
        "\n",
        "# Iterate over the training data\n",
        "for sample in train_data:\n",
        "    # Extract each feature\n",
        "    train_episodes.append(sample['episode'])\n",
        "    train_speakers.append(sample['speakers'])\n",
        "    train_emotions.append(sample['emotions'])\n",
        "    train_utterances.append(sample['utterances'])\n",
        "    train_triggers.append(sample['triggers'])\n",
        "\n",
        "# Initialize lists for each feature in the testing data\n",
        "val_episodes = []\n",
        "val_speakers = []\n",
        "val_emotions = []\n",
        "val_utterances = []\n",
        "val_triggers = []\n",
        "\n",
        "# Iterate over the validation data\n",
        "for sample in val_data:\n",
        "    # Extract each feature\n",
        "    val_episodes.append(sample['episode'])\n",
        "    val_speakers.append(sample['speakers'])\n",
        "    val_emotions.append(sample['emotions'])\n",
        "    val_utterances.append(sample['utterances'])\n",
        "    val_triggers.append(sample['triggers'])"
      ],
      "metadata": {
        "id": "bOqCr3ZdZWtv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HteH1t8xwXy-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, utterances, speakers, emotions, episode, triggers):\n",
        "        self.utterances = utterances\n",
        "        self.speakers = speakers\n",
        "        self.emotions = emotions\n",
        "        self.episode = episode\n",
        "        self.triggers = triggers\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.bert_model = BertModel.from_pretrained('bert-base-uncased').to('cuda')\n",
        "\n",
        "    def generate_embeddings(self, utterances):\n",
        "        embedding_list = []\n",
        "        for utterance in utterances:\n",
        "            tokens = self.tokenizer.encode(utterance, add_special_tokens=True)\n",
        "            tokens_tensor = torch.tensor([tokens]).to('cuda')\n",
        "            with torch.no_grad():\n",
        "                outputs = self.bert_model(tokens_tensor)\n",
        "                last_hidden_state = outputs[0].squeeze(0)  # Take the last hidden state\n",
        "            embedding_list.append(last_hidden_state.cpu().numpy())\n",
        "        return np.vstack(embedding_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.utterances)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        utterances = self.utterances[idx]\n",
        "        speakers = self.speakers[idx]\n",
        "        emotions = self.emotions[idx]\n",
        "        triggers = self.triggers[idx]\n",
        "        z = [i+' '+j+' '+k for i, j, k in zip(utterances, emotions, speakers)]\n",
        "        # Generate embeddings for each utterance\n",
        "        utterance_embeddings = self.generate_embeddings(z)\n",
        "        # Pad embeddings to a fixed length\n",
        "        # print(torch.tensor(triggers).shape)\n",
        "        if len(triggers)>=30:\n",
        "          triggers=triggers[0:30]\n",
        "        else:\n",
        "          triggers=np.array(np.pad(triggers, ((30 - len(triggers)), ( 0)), mode='constant', constant_values=0) ,dtype=np.float32)\n",
        "        triggers=np.array(triggers)\n",
        "        triggers[np.isnan(triggers)] = 0\n",
        "\n",
        "        if  utterance_embeddings.shape[0]<=250:\n",
        "          padded_embeddings =np.array( np.pad(utterance_embeddings, ((0, 250 - utterance_embeddings.shape[0]), (0, 0)), mode='constant', constant_values=0) ,dtype=np.float32)\n",
        "        else:\n",
        "          padded_embeddings =utterance_embeddings[0:250,:]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'utterance_embeddings': torch.tensor(padded_embeddings),\n",
        "            'triggers': torch.tensor(triggers)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train_episodes, train_speakers, train_emotions, train_utterances, train_triggers are lists of lists\n",
        "train_dataset = CustomDataset(train_utterances, train_speakers, train_emotions, train_episodes, train_triggers)\n",
        "val_dataset = CustomDataset(val_utterances, val_speakers, val_emotions, val_episodes, val_triggers)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "GiGdcY6TLr0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "124262c6-ef1c-4398-a22e-1e32118a20a1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-18711fa9e7aa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assuming train_episodes, train_speakers, train_emotions, train_utterances, train_triggers are lists of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_speakers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_triggers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_utterances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_speakers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_emotions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_triggers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-be883c5e9540>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, utterances, speakers, emotions, episode, triggers)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriggers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriggers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-uncased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutterances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2554\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2555\u001b[0m                 )\n\u001b[0;32m-> 2556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1148\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1149\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_loader))\n",
        "print(\"Number of batches in train_loader:\", len(train_loader))\n",
        "print(\"Batch size in train_loader:\", batch_size)\n"
      ],
      "metadata": {
        "id": "iniLmwgM2rlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "# Get a single batch from the train_loader\n",
        "sample_batch = next(iter(train_loader))\n",
        "\n",
        "# Extract input dimensions from the sample batch\n",
        "inputs, labels = sample_batch\n",
        "print(\"Input shape:\", len(inputs))\n",
        "print(\"Labels shape:\", len(labels))\n"
      ],
      "metadata": {
        "id": "_54uH0rs8G0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from transformers import LongformerModel, LongformerTokenizer\n",
        "\n",
        "# class LongformerModel(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "#         super(LongformerModel, self).__init__()\n",
        "#         self.tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "#         self.longformer = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "#         self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         input_ids = self.tokenizer(x, padding=True, truncation=True, return_tensors=\"pt\").input_ids\n",
        "#         outputs = self.longformer(input_ids)\n",
        "#         pooled_output = outputs.last_hidden_state.mean(dim=1)  # Global average pooling\n",
        "#         output = self.fc(pooled_output)\n",
        "#         return output\n",
        "\n",
        "# # Define hyperparameters\n",
        "# hidden_size = 768  # Longformer's hidden size\n",
        "# num_layers = 1  # Number of Longformer layers\n",
        "# num_classes = 2  # Number of output classes\n",
        "\n",
        "# # Instantiate the model\n",
        "# model = LongformerModel(input_size[2], hidden_size, num_layers, num_classes)\n",
        "\n",
        "# # Move model to device\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model.to(device)\n",
        "\n",
        "# # Print model summary\n",
        "# print(model)\n"
      ],
      "metadata": {
        "id": "k7q-L-tEOCKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Get a single batch from the train_loader\n",
        "sample_batch = next(iter(train_loader))\n",
        "\n",
        "# Extract input dimensions from the sample batch\n",
        "input_size = sample_batch['utterance_embeddings'].shape\n",
        "\n",
        "num_classes =sample_batch['triggers'].shape  # Assuming each target is one-hot encoded\n",
        "print(num_classes)\n",
        "# Define BiLSTM model\n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n",
        "        out, _ = self.gru(x, h0)\n",
        "        out = self.fc(out[:, -1, :])  # Use last timestep's output\n",
        "        return out\n",
        "hidden_size = 256\n",
        "num_layers = 1\n",
        "\n",
        "model = GRUModel(input_size[2], hidden_size, num_layers, num_classes[1])\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Print model summary\n",
        "print(model)"
      ],
      "metadata": {
        "id": "bqrzVLg37ouG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(len(train_loader.dataset))\n",
        "# for i in range(len(train_loader.dataset)):\n",
        "#     sample = train_loader.dataset[i]\n",
        "#     inputs, labels = sample['utterances'], sample['triggers']\n",
        "#     print(\"Sample:\", i)\n",
        "#     print(\"Input length:\", len(inputs))\n",
        "#     print(\"Label:\", labels)\n",
        "#     print()\n",
        "#     if i == 5:  # Print only a few samples for inspection\n",
        "#         break\n"
      ],
      "metadata": {
        "id": "CeQ3CHT68Yug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vD0vEiiIjYmu"
      },
      "outputs": [],
      "source": [
        "# def custom_collate(batch):\n",
        "#     max_seq_len = max(len(sample['utterance_embeddings']) for sample in batch)\n",
        "\n",
        "#     # Pad utterance embeddings to the same sequence length\n",
        "#     padded_utterance_embeddings = []\n",
        "#     emotions_list = []\n",
        "#     triggers_list = []\n",
        "#     for sample in batch:\n",
        "#         # Pad embeddings\n",
        "#         padded_utterance_embeddings.append(\n",
        "#             torch.nn.functional.pad(\n",
        "#                 torch.stack(sample['utterance_embeddings']),\n",
        "#                 pad=(0, 0, 0, max_seq_len - len(sample['utterance_embeddings'])),\n",
        "#                 mode='constant',\n",
        "#                 value=0\n",
        "#             )\n",
        "#         )\n",
        "#         emotions_list.append(sample['emotions'])\n",
        "#         triggers_list.append(sample['triggers'])\n",
        "\n",
        "#     return {\n",
        "#         'utterance_embeddings': torch.stack(padded_utterance_embeddings),\n",
        "#         'emotions': emotions_list,\n",
        "#         'triggers': triggers_list\n",
        "#     }\n",
        "\n",
        "# # Assuming train_episodes, train_speakers, train_emotions, train_utterances, train_triggers are lists of lists\n",
        "# train_dataset = CustomDataset(train_utterances, train_speakers, train_emotions, train_episodes, train_triggers)\n",
        "# val_dataset = CustomDataset(val_utterances, val_speakers, val_emotions, val_episodes, val_triggers)\n",
        "\n",
        "# train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=custom_collate)\n",
        "# val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=custom_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mxpxn47-bIJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Move model to device\n",
        "model.to(device)\n",
        "\n",
        "# Define number of classes\n",
        "num_classes = 8  # Assuming there are 8 emotion classes\n",
        "num_epochs = 5\n",
        "epoch = 0\n",
        "# Initialize lists to store losses, accuracies and f1 scores\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "train_f1_scores = []\n",
        "\n",
        "# Set model to training mode\n",
        "model.train()\n",
        "\n",
        "# Define the model parameters and learning rate\n",
        "learning_rate = 0.001\n",
        "params = model.parameters()  # Assuming 'model' is your neural network\n",
        "\n",
        "# Choose an optimizer and specify the learning rate and other parameters\n",
        "optimizer = optim.Adam(params, lr=learning_rate)\n",
        "\n",
        "# Choose a suitable loss function based on your task\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy with Logistic Loss\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Train)\"):\n",
        "        inputs, labels = batch['utterance_embeddings'], batch['triggers']  # Give one hot encoding for label\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.float())  # Use BCEWithLogitsLoss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate total loss\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Threshold predicted labels\n",
        "        predicted_labels = (outputs >= 0.5).float()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        corrects = (predicted_labels == labels).all(dim=-1)\n",
        "        correct = corrects.sum().item()\n",
        "        correct_predictions += correct\n",
        "        total_predictions += labels.numel()\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "    # Calculate average loss and accuracy\n",
        "    average_loss = total_loss / len(train_loader)\n",
        "    train_accuracy = correct_predictions / total_predictions * 100\n",
        "\n",
        "    # Calculate F1 score\n",
        "    train_f1 = f1_score(true_labels, pred_labels, average='macro')\n",
        "    train_f1_scores.append(train_f1)\n",
        "\n",
        "    # Append results to lists\n",
        "    train_losses.append(average_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {average_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%, Training F1 Score: {train_f1:.4f}\")\n",
        "\n",
        "    # Save the model checkpoint for training\n",
        "    model_checkpoint_dir = \"/content/drive/MyDrive/NLP_A4/M4/train_checkpoints\"\n",
        "    os.makedirs(model_checkpoint_dir, exist_ok=True)\n",
        "    model_checkpoint_path = os.path.join(model_checkpoint_dir, f\"epoch_{epoch+1}.pth\")\n",
        "    torch.save(model.state_dict(), model_checkpoint_path)\n",
        "\n",
        "# Plotting the Training Losses vs Epochs\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss vs Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"/content/drive/MyDrive/NLP_A4/M4/train_losses.png\")\n",
        "plt.show()\n",
        "\n",
        "# Save train F1 scores to a file\n",
        "train_f1_file = \"/content/drive/MyDrive/NLP_A4/M4/train_f1_scores.txt\"\n",
        "with open(train_f1_file, \"w\") as f:\n",
        "    for f1 in train_f1_scores:\n",
        "        f.write(str(f1) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Move model to device\n",
        "model.to(device)\n",
        "\n",
        "# Define number of classes\n",
        "num_classes = 8  # Assuming there are 8 emotion classes\n",
        "num_epochs = 5\n",
        "epoch = 0\n",
        "# Initialize lists to store losses, accuracies and f1 scores\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_f1_scores = []\n",
        "\n",
        "# Set model to evaluation mode for validation\n",
        "model.eval()\n",
        "\n",
        "# Choose a suitable loss function based on your task\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy with Logistic Loss\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():  # No need to calculate gradients during validation\n",
        "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\"):\n",
        "            inputs, labels = batch['utterance_embeddings'], batch['triggers']  # Give one hot encoding for label\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels.float())  # Use BCEWithLogitsLoss\n",
        "\n",
        "            # Calculate total loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Threshold predicted labels\n",
        "            predicted_labels = (outputs >= 0.5).float()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            corrects = (predicted_labels == labels).all(dim=-1)\n",
        "            correct = corrects.sum().item()\n",
        "            correct_predictions += correct\n",
        "            total_predictions += labels.numel()\n",
        "\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted_labels.cpu().numpy())\n",
        "\n",
        "    # Calculate average loss and accuracy\n",
        "    average_loss = total_loss / len(val_loader)\n",
        "    val_accuracy = correct_predictions / total_predictions * 100\n",
        "\n",
        "    # Calculate F1 score\n",
        "    val_f1 = f1_score(true_labels, pred_labels, average='macro')\n",
        "    val_f1_scores.append(val_f1)\n",
        "\n",
        "    # Append results to lists\n",
        "    val_losses.append(average_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {average_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%, Validation F1 Score: {val_f1:.4f}\")\n",
        "\n",
        "    # Save the model checkpoint for validation\n",
        "    model_checkpoint_dir = \"/content/drive/MyDrive/NLP_A4/M4/val_checkpoints\"\n",
        "    os.makedirs(model_checkpoint_dir, exist_ok=True)\n",
        "    model_checkpoint_path = os.path.join(model_checkpoint_dir, f\"epoch_{epoch+1}.pth\")\n",
        "    torch.save(model.state_dict(), model_checkpoint_path)\n",
        "\n",
        "# Plotting the Validation Losses vs Epochs\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Validation Loss vs Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"/content/drive/MyDrive/NLP_A4/M4/val_losses.png\")\n",
        "plt.show()\n",
        "\n",
        "# Save validation F1 scores to a file\n",
        "val_f1_file = \"/content/drive/MyDrive/NLP_A4/M4/val_f1_scores.txt\"\n",
        "with open(val_f1_file, \"w\") as f:\n",
        "    for f1 in val_f1_scores:\n",
        "        f.write(str(f1) + \"\\n\")"
      ],
      "metadata": {
        "id": "0q3JiFoUCUtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hPRC-R4hBuli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3fXW6oO_5r4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_loss"
      ],
      "metadata": {
        "id": "2DEloUJiOP5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy"
      ],
      "metadata": {
        "id": "39BU4whEOVnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses"
      ],
      "metadata": {
        "id": "zbQY1lO5OgAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_path = 'M4.pth'\n",
        "\n",
        "# # Save the model\n",
        "# torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "id": "XBM8S4b6ODIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}